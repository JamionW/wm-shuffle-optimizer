# USER EDIT: Modify these settings for your environment

# Spark Configuration - UNCHANGED
spark:
  master: "local[*]"  # Change to "yarn" for Databricks
  app_name: "ML-Shuffle-Optimizer"  # Was: WM-Shuffle-Optimizer
  log_level: "WARN"
  
# Data Configuration - UNCHANGED 
data:
  # USER EDIT: Set to false if you have real Spark cluster
  use_simulation: true
  
  # USER EDIT: Path to your data files (for real mode)
  data_path: "./data"
  
  # Simulation parameters (ignored if use_simulation=false)
  num_partitions: 50 #20
  num_nodes: 4
  synthetic_queries: 500 #100
  
# Model Configuration - CHANGED FROM WM TO ML PARAMETERS
model:
  # REPLACED: nu_init, kappa_init, tau_init with ML parameters
  type: "random_forest"  # Options: "random_forest", "xgboost" 
  n_estimators: 100      # Number of trees
  max_depth: 10          # Maximum tree depth
  min_samples_split: 5   # Minimum samples to split (RF only)
  learning_rate: 0.1     # Learning rate (XGBoost only)
  
# Experiment Configuration - UNCHANGED
experiment:
  train_test_split: 0.7
  random_seed: 42
  output_path: "./results"
  
# USER EDIT: Database connection (for real data) - UNCHANGED
database:
  type: "none"  # Options: "none", "postgres", "mysql", "hive"
  host: "localhost"
  port: 5432
  database: "testdb"
  username: "user"
  password: "pass"